{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度卷积网络定义\n",
    "\n",
    "https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch08/deep_convnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为导入父目录中的文件而进行的设置\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "\n",
    "\n",
    "class DeepConvNet:\n",
    "    \"\"\"识别率达99%以上的高精度ConvNet\n",
    "    网络构成如下所示\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        affine - relu - dropout - affine - dropout - softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n",
    "                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 hidden_size=50, output_size=10):\n",
    "        # 权重初始化===========\n",
    "        # 每层的每个神经元与前面层的神经元有几个连接（TODO:自动计算）\n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        weight_init_scales = np.sqrt(2.0 / pre_node_nums)  # 使用ReLU时推荐的初始值\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params['W' + str(idx+1)] = weight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "        self.params['W7'] = weight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = weight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "\n",
    "        # 生成层===========\n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], \n",
    "                           conv_param_1['stride'], conv_param_1['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], \n",
    "                           conv_param_2['stride'], conv_param_2['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W3'], self.params['b3'], \n",
    "                           conv_param_3['stride'], conv_param_3['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n",
    "                           conv_param_4['stride'], conv_param_4['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n",
    "                           conv_param_5['stride'], conv_param_5['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n",
    "                           conv_param_6['stride'], conv_param_6['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 设置\n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
    "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
    "            self.layers[layer_idx].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练上面的网络\n",
    "\n",
    "https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch08/train_deepnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4015404472899804\n",
      "=== epoch:1, train acc:0.161, test acc:0.162 ===\n",
      "train loss:2.313922172333037\n",
      "train loss:2.2858850888317157\n",
      "train loss:2.354265425877489\n",
      "train loss:2.274176970261442\n",
      "train loss:2.268857182259396\n",
      "train loss:2.234013474896587\n",
      "train loss:2.263062360321933\n",
      "train loss:2.2661067091237594\n",
      "train loss:2.255342243624122\n",
      "train loss:2.263935404669674\n",
      "train loss:2.245219664967881\n",
      "train loss:2.241985033736336\n",
      "train loss:2.2267605410514886\n",
      "train loss:2.1777569863816324\n",
      "train loss:2.200669687623499\n",
      "train loss:2.145830083821732\n",
      "train loss:2.1438538382433787\n",
      "train loss:2.1590821086262797\n",
      "train loss:2.1103921350375585\n",
      "train loss:2.118717059497033\n",
      "train loss:2.1253354848900026\n",
      "train loss:1.9944096453651485\n",
      "train loss:1.9740180039991904\n",
      "train loss:2.069660982358959\n",
      "train loss:2.088286182894281\n",
      "train loss:2.0491245677875454\n",
      "train loss:1.9247030946844996\n",
      "train loss:1.9757064176854557\n",
      "train loss:1.982554251459761\n",
      "train loss:1.9109074832490018\n",
      "train loss:1.833994083028639\n",
      "train loss:1.900529348762171\n",
      "train loss:1.8560484855969914\n",
      "train loss:1.887646210928019\n",
      "train loss:1.9445028814238399\n",
      "train loss:1.935342184126042\n",
      "train loss:1.8222054421414402\n",
      "train loss:1.810293923987952\n",
      "train loss:1.8246918558057508\n",
      "train loss:1.77011503867194\n",
      "train loss:1.8054756073205167\n",
      "train loss:2.0801084413558093\n",
      "train loss:1.9733835309584067\n",
      "train loss:1.831022450273073\n",
      "train loss:1.7760680260277422\n",
      "train loss:1.9538767290771204\n",
      "train loss:1.9277586260537487\n",
      "train loss:1.937474694606333\n",
      "train loss:1.7972419517907252\n",
      "train loss:1.6005535860719675\n",
      "train loss:1.7560203991632641\n",
      "train loss:1.7200168920460852\n",
      "train loss:1.7173599603165597\n",
      "train loss:1.8008693419678077\n",
      "train loss:1.787543356408411\n",
      "train loss:1.7560292237947146\n",
      "train loss:1.84468763315235\n",
      "train loss:1.667780694251608\n",
      "train loss:1.5753474919980368\n",
      "train loss:1.739003332841931\n",
      "train loss:1.7117322752367345\n",
      "train loss:1.704513741823304\n",
      "train loss:1.6424972829142812\n",
      "train loss:1.684904908188392\n",
      "train loss:1.7359874854415311\n",
      "train loss:1.519902333639958\n",
      "train loss:1.70865735729717\n",
      "train loss:1.7435449064678814\n",
      "train loss:1.7186500775221987\n",
      "train loss:1.6689948638414855\n",
      "train loss:1.6120142594361835\n",
      "train loss:1.7092659688812502\n",
      "train loss:1.4359726824185566\n",
      "train loss:1.6037073943724662\n",
      "train loss:1.585169617475666\n",
      "train loss:1.6180260182127513\n",
      "train loss:1.6997276683262041\n",
      "train loss:1.829773228010066\n",
      "train loss:1.6508113876256627\n",
      "train loss:1.6064695201421142\n",
      "train loss:1.4596411746018492\n",
      "train loss:1.6377920925431306\n",
      "train loss:1.5794476011195284\n",
      "train loss:1.829570663090709\n",
      "train loss:1.4954736665275692\n",
      "train loss:1.855185787541545\n",
      "train loss:1.621628501456374\n",
      "train loss:1.5600563940087242\n",
      "train loss:1.544063306045451\n",
      "train loss:1.6011124647216946\n",
      "train loss:1.6508920450063889\n",
      "train loss:1.5727896451424948\n",
      "train loss:1.6530527133686936\n",
      "train loss:1.594595914798865\n",
      "train loss:1.4970942681068717\n",
      "train loss:1.4919699204109866\n",
      "train loss:1.6712202949169757\n",
      "train loss:1.5352437756483872\n",
      "train loss:1.479711227450964\n",
      "train loss:1.5180006951268359\n",
      "train loss:1.51994927454898\n",
      "train loss:1.4904002627625956\n",
      "train loss:1.648435255097293\n",
      "train loss:1.5848371072816985\n",
      "train loss:1.39448587641428\n",
      "train loss:1.5088117093627011\n",
      "train loss:1.4933799805555776\n",
      "train loss:1.5594366126073091\n",
      "train loss:1.5052772097412466\n",
      "train loss:1.4742509268658048\n",
      "train loss:1.5798056216674246\n",
      "train loss:1.3548103218507674\n",
      "train loss:1.4269987241444921\n",
      "train loss:1.4397667500758913\n",
      "train loss:1.522283168939473\n",
      "train loss:1.656387042274198\n",
      "train loss:1.5748529841824337\n",
      "train loss:1.1000724617208315\n",
      "train loss:1.4149803656689999\n",
      "train loss:1.4597886245448768\n",
      "train loss:1.3155619752684953\n",
      "train loss:1.5331522246783096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-96a0e13f37c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_param\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                   evaluate_sample_num_per_epoch=1000)\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# 保存参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\deeplearning_from_scratch\\common\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\deeplearning_from_scratch\\common\\trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mt_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-8b453f9907d2>\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mtmp_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtmp_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# 设置\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\deeplearning_from_scratch\\common\\layers.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mdcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol_W\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol2im\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\deeplearning_from_scratch\\common\\util.py\u001b[0m in \u001b[0;36mcol2im\u001b[1;34m(col, input_shape, filter_h, filter_w, stride, pad)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mx_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout_w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为导入父目录中的文件而进行的设置\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "#from deep_convnet import DeepConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=20, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 保存参数\n",
    "network.save_params(\"deep_convnet_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 半精度浮点数网络\n",
    "\n",
    "https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch08/half_float_network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caluculate accuracy (float64) ... \n",
      "0.9935\n",
      "caluculate accuracy (float16) ... \n",
      "0.9935\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为导入父目录中的文件而进行的设置\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from deep_convnet import DeepConvNet\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "sampled = 10000 # 为了运行更快速\n",
    "x_test = x_test[:sampled]\n",
    "t_test = t_test[:sampled]\n",
    "\n",
    "print(\"caluculate accuracy (float64) ... \")\n",
    "print(network.accuracy(x_test, t_test))\n",
    "\n",
    "# 类型变化为float16\n",
    "x_test = x_test.astype(np.float16)\n",
    "for param in network.params.values():\n",
    "    param[...] = param.astype(np.float16)\n",
    "\n",
    "print(\"caluculate accuracy (float16) ... \")\n",
    "print(network.accuracy(x_test, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类错误的图片\n",
    "\n",
    "https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch08/misclassified_mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating test accuracy ... \n",
      "test accuracy:0.9935\n",
      "======= misclassified result =======\n",
      "{view index: (label, inference), ...}\n",
      "{1: (6, 0), 2: (3, 5), 3: (3, 5), 4: (8, 3), 5: (7, 3), 6: (1, 3), 7: (8, 9), 8: (6, 0), 9: (6, 5), 10: (7, 2), 11: (9, 4), 12: (7, 1), 13: (5, 3), 14: (1, 3), 15: (0, 6), 16: (9, 4), 17: (7, 9), 18: (6, 0), 19: (9, 8), 20: (4, 9)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为导入父目录中的文件而进行的设置\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from deep_convnet import DeepConvNet\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "print(\"calculating test accuracy ... \")\n",
    "#sampled = 1000\n",
    "#x_test = x_test[:sampled]\n",
    "#t_test = t_test[:sampled]\n",
    "\n",
    "classified_ids = []\n",
    "\n",
    "acc = 0.0\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(int(x_test.shape[0] / batch_size)):\n",
    "    tx = x_test[i*batch_size:(i+1)*batch_size]\n",
    "    tt = t_test[i*batch_size:(i+1)*batch_size]\n",
    "    y = network.predict(tx, train_flg=False)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    classified_ids.append(y)\n",
    "    acc += np.sum(y == tt)\n",
    "    \n",
    "acc = acc / x_test.shape[0]\n",
    "print(\"test accuracy:\" + str(acc))\n",
    "\n",
    "classified_ids = np.array(classified_ids)\n",
    "classified_ids = classified_ids.flatten()\n",
    " \n",
    "max_view = 20\n",
    "current_view = 1\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.2, wspace=0.2)\n",
    "\n",
    "mis_pairs = {}\n",
    "for i, val in enumerate(classified_ids == t_test):\n",
    "    if not val:\n",
    "        ax = fig.add_subplot(4, 5, current_view, xticks=[], yticks=[])\n",
    "        ax.imshow(x_test[i].reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        mis_pairs[current_view] = (t_test[i], classified_ids[i])\n",
    "            \n",
    "        current_view += 1\n",
    "        if current_view > max_view:\n",
    "            break\n",
    "\n",
    "print(\"======= misclassified result =======\")\n",
    "print(\"{view index: (label, inference), ...}\")\n",
    "print(mis_pairs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建你自己的了不起的网络\n",
    "\n",
    "https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch08/awesome_net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your awesome net!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
